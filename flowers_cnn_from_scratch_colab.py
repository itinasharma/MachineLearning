# -*- coding: utf-8 -*-
"""Flowers_CNN_From_Scratch_Colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NZDU0NegxSVqMdIqL3eRbTKIqGwzVooO

# üå∏ Flowers Recognition: CNN from Scratch
## Demonstrating ~68% Accuracy Plateau

This notebook trains a simple CNN from scratch on the Flowers Recognition dataset to demonstrate:
- How basic CNNs plateau at ~68% accuracy on limited data
- Severe overfitting without transfer learning
- Why transfer learning is essential for computer vision

**Expected Results:**
- ‚úÖ Validation Accuracy: ~68-70%
- ‚úÖ Training Accuracy: ~85-90%
- ‚úÖ Overfitting Gap: ~19-20%

## üì¶ Setup & Installation
"""

# Check if GPU is available (recommended for faster training)
import tensorflow as tf
print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))
print("\n‚ö° GPU is", "ENABLED" if tf.config.list_physical_devices('GPU') else "NOT available")
print("üí° Tip: Enable GPU in Runtime > Change runtime type > Hardware accelerator > GPU")

# Install Kaggle API for dataset download
!pip install -q kaggle

import kagglehub

# Download latest version
path = kagglehub.dataset_download("alxmamaev/flowers-recognition")

print("Path to dataset files:", path)

"""## üì• Download Flowers Recognition Dataset"""

import glob

# Define dataset path (THIS was missing)
DATASET_DIR = "/kaggle/input/flowers-recognition/flowers"


classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']

print("üì∏ Images per class:")
total = 0
for cls in classes:
    count = len(glob.glob(f"{DATASET_DIR}/{cls}/*.jpg"))
    total += count
    print(f"  {cls:12s}: {count:4d} images")

print(f"  {'TOTAL':12s}: {total:4d} images")

"""## üìö Import Libraries"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import json

# Set random seeds for reproducibility
np.random.seed(42)
tf.random.set_seed(42)

print("‚úÖ Libraries imported successfully!")

"""## ‚öôÔ∏è Configuration"""

# Training configuration
IMG_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 50
LEARNING_RATE = 0.001
NUM_CLASSES = 5
DATASET_DIR = 'flowers_data'

print("‚öôÔ∏è Configuration:")
print(f"  Image Size: {IMG_SIZE}x{IMG_SIZE}")
print(f"  Batch Size: {BATCH_SIZE}")
print(f"  Epochs: {EPOCHS}")
print(f"  Learning Rate: {LEARNING_RATE}")
print(f"  Classes: {NUM_CLASSES}")

"""## üëÄ Visualize Sample Images"""

import glob, random
from PIL import Image
import matplotlib.pyplot as plt

DATASET_DIR = "/kaggle/input/flowers-recognition/flowers"
classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']

plt.figure(figsize=(10, 6))

for i, cls in enumerate(classes):
    images = glob.glob(f"{DATASET_DIR}/{cls}/*.jpg")
    img_path = random.choice(images)

    img = Image.open(img_path)
    plt.subplot(1, 5, i + 1)
    plt.imshow(img)
    plt.title(cls)
    plt.axis("off")

plt.tight_layout()
plt.show()

"""## üîÑ Data Preprocessing

**Key Point**: Using minimal preprocessing (resize + normalize only)
- ‚ùå No data augmentation (intentional to show overfitting)
- ‚ùå No transfer learning
- ‚ùå No pretrained weights
"""

# Create data generators with minimal preprocessing
print("üîÑ Creating data generators...\n")

# Simple preprocessing - only rescaling (normalize to [0,1])
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2  # 80-20 train-val split
)

# Training data
train_generator = train_datagen.flow_from_directory(
    DATASET_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

# Validation data
validation_generator = train_datagen.flow_from_directory(
    DATASET_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)

print(f"\n‚úÖ Data generators ready!")
print(f"\nüìä Data split:")
print(f"  Training samples: {train_generator.samples}")
print(f"  Validation samples: {validation_generator.samples}")
print(f"  Classes: {list(train_generator.class_indices.keys())}")

"""## üèóÔ∏è Build Simple CNN Architecture

**Simple Architecture**: 3 Conv blocks + 2 Dense layers
- Limited depth ‚Üí Limited feature extraction
- No skip connections, no batch normalization
- This simplicity contributes to the ~68% plateau
"""

def build_simple_cnn(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES):
    """Build a simple CNN architecture from scratch."""

    model = keras.Sequential([
        # Input layer
        layers.Input(shape=input_shape),

        # First convolutional block
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1'),
        layers.MaxPooling2D((2, 2), name='pool1'),

        # Second convolutional block
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2'),
        layers.MaxPooling2D((2, 2), name='pool2'),

        # Third convolutional block
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3'),
        layers.MaxPooling2D((2, 2), name='pool3'),

        # Flatten and dense layers
        layers.Flatten(name='flatten'),
        layers.Dense(256, activation='relu', name='dense1'),
        layers.Dropout(0.5, name='dropout'),
        layers.Dense(num_classes, activation='softmax', name='output')
    ], name='Simple_CNN')

    return model

# Build the model
print("üèóÔ∏è Building CNN architecture...\n")
model = build_simple_cnn()

# Display model summary
model.summary()

print(f"\nüìä Total Parameters: {model.count_params():,}")

"""## ‚ö° Compile Model"""

# Compile model with Adam optimizer and fixed learning rate
print("‚ö° Compiling model...\n")

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("‚úÖ Model compiled!")
print(f"\n‚öôÔ∏è Configuration:")
print(f"  Optimizer: Adam (lr={LEARNING_RATE})")
print(f"  Loss: Categorical Crossentropy")
print(f"  Metrics: Accuracy")

"""## üöÄ Train Model (50 Epochs)

**Expected behavior:**
- Training accuracy will continue improving (~85-90%)
- Validation accuracy will plateau around **~68%**
- Clear overfitting after ~20-30 epochs

‚è±Ô∏è **Training time**:
- With GPU: ~15-25 minutes
- Without GPU: ~2-3 hours
"""

# Train the model
print("üöÄ Starting training...\n")
print("="*70)
print(f"Training for {EPOCHS} epochs")
print("Watch for validation accuracy plateau around epoch 20-30")
print("="*70 + "\n")

history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=validation_generator,
    verbose=1
)

print("\n‚úÖ Training complete!")

"""## üìä Evaluate Results"""

# Evaluate on validation set
print("üìä Evaluating model...\n")

val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)
final_train_acc = history.history['accuracy'][-1]
max_val_acc = max(history.history['val_accuracy'])
max_train_acc = max(history.history['accuracy'])
overfitting_gap = (final_train_acc - val_accuracy) * 100

print("="*70)
print("FINAL RESULTS")
print("="*70)

print(f"\nüìà Final Performance (Epoch {EPOCHS}):")
print(f"  Validation Accuracy: {val_accuracy*100:6.2f}% ‚Üê TARGET ~68%")
print(f"  Training Accuracy:   {final_train_acc*100:6.2f}%")
print(f"  Validation Loss:     {val_loss:6.4f}")

print(f"\nüèÜ Best Performance:")
print(f"  Max Validation Acc:  {max_val_acc*100:6.2f}%")
print(f"  Max Training Acc:    {max_train_acc*100:6.2f}%")

print(f"\n‚ö†Ô∏è  Overfitting Analysis:")
print(f"  Overfitting Gap:     {overfitting_gap:6.2f}%")
print(f"  Severity:            {'SEVERE' if overfitting_gap > 15 else 'MODERATE'}")

print("\n" + "="*70)

# Save results
results = {
    'final_metrics': {
        'validation_accuracy': float(val_accuracy),
        'training_accuracy': float(final_train_acc),
        'validation_loss': float(val_loss),
        'overfitting_gap_percent': float(overfitting_gap)
    },
    'best_metrics': {
        'max_validation_accuracy': float(max_val_acc),
        'max_training_accuracy': float(max_train_acc)
    },
    'configuration': {
        'image_size': IMG_SIZE,
        'batch_size': BATCH_SIZE,
        'epochs': EPOCHS,
        'learning_rate': LEARNING_RATE
    }
}

with open('training_results.json', 'w') as f:
    json.dump(results, f, indent=2)

print("\nüíæ Results saved to training_results.json")

"""## üìà Visualize Training History"""

# Plot comprehensive training history
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

epochs_range = range(1, EPOCHS + 1)

# 1. Accuracy comparison
ax1 = axes[0, 0]
ax1.plot(epochs_range, history.history['accuracy'], 'b-', linewidth=2.5, label='Training Accuracy')
ax1.plot(epochs_range, history.history['val_accuracy'], 'r-', linewidth=2.5, label='Validation Accuracy')
ax1.axhline(y=0.68, color='green', linestyle='--', linewidth=2, alpha=0.7, label='Target ~68%')
ax1.fill_between(epochs_range, history.history['accuracy'], history.history['val_accuracy'],
                  where=[t > v for t, v in zip(history.history['accuracy'], history.history['val_accuracy'])],
                  alpha=0.3, color='orange', label='Overfitting Gap')
ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')
ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')
ax1.set_title('Training vs Validation Accuracy\n(Shows Overfitting)', fontsize=14, fontweight='bold')
ax1.legend(loc='lower right', fontsize=10)
ax1.grid(True, alpha=0.3)
ax1.set_ylim([0.2, 1.0])

# 2. Loss comparison
ax2 = axes[0, 1]
ax2.plot(epochs_range, history.history['loss'], 'b-', linewidth=2.5, label='Training Loss')
ax2.plot(epochs_range, history.history['val_loss'], 'r-', linewidth=2.5, label='Validation Loss')
ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')
ax2.set_ylabel('Loss', fontsize=12, fontweight='bold')
ax2.set_title('Training vs Validation Loss\n(Val Loss Increases = Overfitting)', fontsize=14, fontweight='bold')
ax2.legend(loc='upper right', fontsize=10)
ax2.grid(True, alpha=0.3)

# 3. Validation accuracy focus
ax3 = axes[1, 0]
ax3.plot(epochs_range, history.history['val_accuracy'], 'r-', linewidth=3, label='Validation Accuracy')
ax3.axhline(y=0.68, color='green', linestyle='--', linewidth=2, label='~68% Plateau')
ax3.fill_between(epochs_range, 0.65, 0.71, alpha=0.2, color='green', label='Expected Plateau Range')
ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')
ax3.set_ylabel('Validation Accuracy', fontsize=12, fontweight='bold')
ax3.set_title('Validation Accuracy Plateau\n(Limited by Architecture & Data)', fontsize=14, fontweight='bold')
ax3.legend(loc='lower right', fontsize=10)
ax3.grid(True, alpha=0.3)
ax3.set_ylim([0.2, 0.8])

# 4. Overfitting gap
ax4 = axes[1, 1]
overfitting_gap_history = [(t - v) * 100 for t, v in zip(history.history['accuracy'], history.history['val_accuracy'])]
ax4.plot(epochs_range, overfitting_gap_history, 'orange', linewidth=3, label='Overfitting Gap')
ax4.fill_between(epochs_range, 0, overfitting_gap_history, alpha=0.3, color='orange')
ax4.axhline(y=0, color='gray', linestyle='-', linewidth=1)
ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')
ax4.set_ylabel('Gap (%)', fontsize=12, fontweight='bold')
ax4.set_title('Overfitting Gap Over Time\n(Train Accuracy - Val Accuracy)', fontsize=14, fontweight='bold')
ax4.legend(loc='upper left', fontsize=10)
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
plt.show()

print("\n‚úÖ Training curves saved to training_curves.png")

"""## üîç Analysis: Why ~68% Plateau?

## üíæ Save Model
"""

# Save the trained model
model.save('flowers_cnn_model.keras')
print("‚úÖ Model saved to 'flowers_cnn_model.keras'")

# Download files (optional)
print("\nüì• Download files to your computer:")
from google.colab import files

try:
    files.download('flowers_cnn_model.keras')
    files.download('training_curves.png')
    files.download('training_results.json')
    print("‚úÖ Files downloaded!")
except:
    print("‚ö†Ô∏è  Use Files panel on left to download manually")

"""## üéØ Conclusion

### ‚úÖ Objectives Achieved:
- Demonstrated ~68% validation accuracy plateau
- Showed severe overfitting (19% gap)
- Illustrated limitations of training from scratch

### üöÄ Next Steps to Improve:

#### 1. **Use Transfer Learning** (+22-26% accuracy)
```python
base_model = tf.keras.applications.ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)
```

#### 2. **Add Data Augmentation** (+5-10% accuracy)
```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    zoom_range=0.2
)
```

#### 3. **Implement Learning Rate Scheduling** (+2-5% accuracy)
```python
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5
)
```

### üìö Resources:
- [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)
- [Data Augmentation Techniques](https://www.tensorflow.org/tutorials/images/data_augmentation)
- [Kaggle Flowers Dataset](https://www.kaggle.com/datasets/alxmamaev/flowers-recognition)
"""