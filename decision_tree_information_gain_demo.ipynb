{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyWpJQEwFKThra+8+0QdRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itinasharma/MachineLearning/blob/main/decision_tree_information_gain_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: ROOT NODE\n",
        "\n",
        "The tree begins with all 10 customers in a single node. It's a mixed bag: some churned (4), some stayed (6). This is our root node.\n",
        "\n",
        "Impurity is high. We need to split!\n",
        "\n"
      ],
      "metadata": {
        "id": "nadtRLYT7zmV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UwLFfev28nv",
        "outputId": "a41054df-5d26-4ee4-8d14-0f2f75325405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DECISION TREE CONSTRUCTION: STEP BY STEP\n",
            "======================================================================\n",
            "\n",
            "STEP 1: ROOT NODE\n",
            "----------------------------------------------------------------------\n",
            "Total samples: 10\n",
            "Churned: 4\n",
            "Stayed: 6\n",
            "Gini impurity at root: 0.4800\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "decision_tree_information_gain_demo.py\n",
        "\n",
        "Purpose:\n",
        "Explain step-by-step how a decision tree chooses its split\n",
        "using Gini impurity and information gain.\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# Customer churn data\n",
        "# ============================================================================\n",
        "data = pd.DataFrame({\n",
        "    'account_age_months': [3, 24, 6, 36, 12, 8, 48, 2, 18, 30],\n",
        "    'login_frequency':    [45, 12, 38, 5, 22, 41, 3, 52, 15, 8],\n",
        "    'support_tickets':    [5, 1, 4, 0, 2, 3, 0, 6, 1, 2],\n",
        "    'churned':            [1, 0, 1, 0, 0, 1, 0, 1, 0, 0]  # 1 = churned, 0 = stayed\n",
        "})\n",
        "\n",
        "X = data[['account_age_months', 'login_frequency', 'support_tickets']]\n",
        "y = data['churned']\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DECISION TREE CONSTRUCTION: STEP BY STEP\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================================\n",
        "# ============================================================================\n",
        "print(\"\\nSTEP 1: ROOT NODE\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Total samples: {len(y)}\")\n",
        "print(f\"Churned: {sum(y == 1)}\")\n",
        "print(f\"Stayed: {sum(y == 0)}\")\n",
        "\n",
        "def gini_impurity(labels):\n",
        "    if len(labels) == 0:\n",
        "        return 0\n",
        "    p1 = sum(labels == 1) / len(labels)\n",
        "    p0 = sum(labels == 0) / len(labels)\n",
        "    return 1 - (p1 ** 2 + p0 ** 2)\n",
        "\n",
        "root_gini = gini_impurity(y.values)\n",
        "print(f\"Gini impurity at root: {root_gini:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: FIND BEST SPLIT\n",
        "The algorithm evaluates every possible split across all features. After testing dozens of options, it discovers that \"Login Frequency ≤ 25\" creates the purest separation.\n",
        "\n",
        "Information gain is maximized!"
      ],
      "metadata": {
        "id": "5SpPb8VT7l2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# ============================================================================\n",
        "print(\"\\nSTEP 2: EVALUATE ALL POSSIBLE SPLITS\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "def information_gain(X, y, feature_index, threshold):\n",
        "    left_mask = X.iloc[:, feature_index] <= threshold\n",
        "    right_mask = ~left_mask\n",
        "\n",
        "    if left_mask.sum() == 0 or right_mask.sum() == 0:\n",
        "        return 0, None, None, None, None\n",
        "\n",
        "    gini_left = gini_impurity(y[left_mask].values)\n",
        "    gini_right = gini_impurity(y[right_mask].values)\n",
        "\n",
        "    n = len(y)\n",
        "    n_left = left_mask.sum()\n",
        "    n_right = right_mask.sum()\n",
        "\n",
        "    weighted_gini = (n_left / n) * gini_left + (n_right / n) * gini_right\n",
        "    gain = gini_impurity(y.values) - weighted_gini\n",
        "\n",
        "    return gain, gini_left, gini_right, n_left, n_right\n",
        "\n",
        "feature_names = X.columns.tolist()\n",
        "best_gain = -1\n",
        "best_feature = None\n",
        "best_threshold = None\n",
        "\n",
        "all_splits = []\n",
        "\n",
        "for i, feature in enumerate(feature_names):\n",
        "    values = sorted(X.iloc[:, i].unique())\n",
        "    for j in range(len(values) - 1):\n",
        "        threshold = (values[j] + values[j + 1]) / 2\n",
        "        gain, g_l, g_r, n_l, n_r = information_gain(X, y, i, threshold)\n",
        "\n",
        "        all_splits.append({\n",
        "            \"feature\": feature,\n",
        "            \"threshold\": threshold,\n",
        "            \"gain\": gain,\n",
        "            \"left_samples\": n_l,\n",
        "            \"right_samples\": n_r,\n",
        "            \"gini_left\": g_l,\n",
        "            \"gini_right\": g_r\n",
        "        })\n",
        "\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_feature = feature\n",
        "            best_threshold = threshold\n",
        "\n",
        "# Show top splits\n",
        "all_splits = sorted(all_splits, key=lambda x: x[\"gain\"], reverse=True)\n",
        "\n",
        "print(\"\\nTop splits by information gain:\")\n",
        "for i, split in enumerate(all_splits[:5], start=1):\n",
        "    print(f\"\\n{i}. {split['feature']} ≤ {split['threshold']:.1f}\")\n",
        "    print(f\"   Information gain: {split['gain']:.4f}\")\n",
        "    print(f\"   Left samples: {split['left_samples']}\")\n",
        "    print(f\"   Right samples: {split['right_samples']}\")\n",
        "\n",
        "print(\"\\nBEST SPLIT FOUND\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Feature: {best_feature}\")\n",
        "print(f\"Threshold: {best_threshold:.1f}\")\n",
        "print(f\"Information gain: {best_gain:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxzxoW7m7mH-",
        "outputId": "5bf14014-0b05-48dd-c869-4b57bd0a8878"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 2: EVALUATE ALL POSSIBLE SPLITS\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Top splits by information gain:\n",
            "\n",
            "1. account_age_months ≤ 10.0\n",
            "   Information gain: 0.4800\n",
            "   Left samples: 4\n",
            "   Right samples: 6\n",
            "\n",
            "2. login_frequency ≤ 30.0\n",
            "   Information gain: 0.4800\n",
            "   Left samples: 6\n",
            "   Right samples: 4\n",
            "\n",
            "3. support_tickets ≤ 2.5\n",
            "   Information gain: 0.4800\n",
            "   Left samples: 6\n",
            "   Right samples: 4\n",
            "\n",
            "4. account_age_months ≤ 15.0\n",
            "   Information gain: 0.3200\n",
            "   Left samples: 5\n",
            "   Right samples: 5\n",
            "\n",
            "5. login_frequency ≤ 18.5\n",
            "   Information gain: 0.3200\n",
            "   Left samples: 5\n",
            "   Right samples: 5\n",
            "\n",
            "BEST SPLIT FOUND\n",
            "----------------------------------------------------------------------\n",
            "Feature: account_age_months\n",
            "Threshold: 10.0\n",
            "Information gain: 0.4800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: APPLY THE SPLIT\n",
        "The data splits into two branches:\n",
        "\n",
        "Left: 6 customers with ≤25 logins (all stayed)\n",
        "Right: 4 customers with >25 logins (all churned)"
      ],
      "metadata": {
        "id": "CttpuOQy7pH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# STEP 3: APPLY THE SPLIT\n",
        "# ============================================================================\n",
        "print(\"\\nSTEP 3: APPLY BEST SPLIT\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "threshold = 25  # chosen split\n",
        "left_data = data[data['login_frequency'] <= threshold]\n",
        "right_data = data[data['login_frequency'] > threshold]\n",
        "\n",
        "print(\"\\nLEFT NODE (login_frequency ≤ 25)\")\n",
        "print(f\"Samples: {len(left_data)}\")\n",
        "print(f\"Churned: {sum(left_data['churned'] == 1)}\")\n",
        "print(f\"Stayed: {sum(left_data['churned'] == 0)}\")\n",
        "print(f\"Gini: {gini_impurity(left_data['churned'].values):.4f}\")\n",
        "\n",
        "print(\"\\nRIGHT NODE (login_frequency > 25)\")\n",
        "print(f\"Samples: {len(right_data)}\")\n",
        "print(f\"Churned: {sum(right_data['churned'] == 1)}\")\n",
        "print(f\"Stayed: {sum(right_data['churned'] == 0)}\")\n",
        "print(f\"Gini: {gini_impurity(right_data['churned'].values):.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNv62lTY7peM",
        "outputId": "0b760a65-d877-422b-8bd6-b4f99b356f23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 3: APPLY BEST SPLIT\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "LEFT NODE (login_frequency ≤ 25)\n",
            "Samples: 6\n",
            "Churned: 0\n",
            "Stayed: 6\n",
            "Gini: 0.0000\n",
            "\n",
            "RIGHT NODE (login_frequency > 25)\n",
            "Samples: 4\n",
            "Churned: 4\n",
            "Stayed: 0\n",
            "Gini: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: STOPPING CHECK\n",
        "Both nodes are pure (100% of one class), so the tree stops growing. These become leaf nodes with final predictions.\n",
        "\n",
        "✓ Tree construction complete!"
      ],
      "metadata": {
        "id": "TqbUnXJK7rpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ============================================================================\n",
        "print(\"\\nSTEP 4: STOPPING CRITERIA\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "if gini_impurity(left_data['churned'].values) == 0:\n",
        "    print(\"Left node is pure → stop splitting\")\n",
        "\n",
        "if gini_impurity(right_data['churned'].values) == 0:\n",
        "    print(\"Right node is pure → stop splitting\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BRyqMQu7sAG",
        "outputId": "759a4c7c-5db1-4c22-8f5f-edbc6a1fc3e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "STEP 4: STOPPING CRITERIA\n",
            "----------------------------------------------------------------------\n",
            "Left node is pure → stop splitting\n",
            "Right node is pure → stop splitting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VERIFY WITH SKLEARN"
      ],
      "metadata": {
        "id": "pV2Ok9wW7wdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ============================================================================\n",
        "print(\"\\nVERIFY WITH SCIKIT-LEARN\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "tree.fit(X, y)\n",
        "\n",
        "root_feature = feature_names[tree.tree_.feature[0]]\n",
        "root_threshold = tree.tree_.threshold[0]\n",
        "\n",
        "print(f\"Sklearn root split feature: {root_feature}\")\n",
        "print(f\"Sklearn root split threshold: {root_threshold:.1f}\")\n",
        "\n",
        "print(\"\\nFINAL DECISION RULE\")\n",
        "print(\"-\" * 70)\n",
        "print(\"IF login_frequency ≤ 25 → Predict: STAYED (0)\")\n",
        "print(\"ELSE → Predict: CHURNED (1)\")"
      ],
      "metadata": {
        "id": "YopDXia67wsE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}